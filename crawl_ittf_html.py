import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import pandas as pd
import time
import re

targetYear=2021


# ====== 1. è¯»å–å·²æœ‰æ•°æ® ======
csv_file = f"ittf_women_{targetYear}_rankings.csv"
try:
    existing_df = pd.read_csv(csv_file)
    print(f"âœ… å·²åŠ è½½ {len(existing_df)} æ¡å·²æœ‰æ•°æ®")
except FileNotFoundError:
    existing_df = pd.DataFrame()
    print("âš ï¸  æœªæ‰¾åˆ°å·²æœ‰ CSVï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")

# ====== 2. å®šä¹‰èŽ·å–å‘å¸ƒæ—¥æœŸçš„å‡½æ•° ======
def get_ranking_release_date(year, week_num):
    jan_4 = datetime(year, 1, 4)
    monday_week1 = jan_4 - timedelta(days=jan_4.weekday())
    target_monday = monday_week1 + timedelta(weeks=week_num - 1)
    return target_monday + timedelta(days=1)

def extract_association(td_element):
    """
    ä»Ž td å…ƒç´ ä¸­æå–åä¼šä»£ç ï¼ˆå¦‚ CHNã€JPNï¼‰
    æ”¯æŒä¸åŒå¹´ä»½çš„ HTML ç»“æž„
    """
    # æ–¹æ³•1ï¼šå°è¯•ä»Ž p çš„ class ä¸­æå–ï¼ˆ2024+ å¹´ï¼‰
    p_tag = td_element.find('p')
    if p_tag and p_tag.get('class'):
        for cls in p_tag['class']:
            if cls.startswith('fg-'):
                return cls.split('-', 1)[1]  # å– 'fg-CHN' ä¸­çš„ CHN

    # æ–¹æ³•2ï¼šç›´æŽ¥ä»Ž td æ–‡æœ¬æå–ï¼ˆ2023 å¹´ç­‰æ—§ç»“æž„ï¼‰
    text = td_element.get_text(strip=True)
    if text and len(text) in (2, 3) and text.isalpha():
        return text

    return None  # æ— æ³•æå–

# ====== 3. åªçˆ¬ç¬¬1â€“9å‘¨ ======
new_data = []

for week in range(10, 53):  # ç¬¬1åˆ°ç¬¬52å‘¨
    release_date = get_ranking_release_date(targetYear, week)
    year_dir = release_date.strftime('%Y')
    month_dir = release_date.strftime('%m')
    filename = f"{targetYear}_{week}_SEN_WS.html"
    url = f"https://www.ittf.com/wp-content/uploads/{year_dir}/{month_dir}/{filename}"

    # æ£€æŸ¥æ˜¯å¦å·²ç»çˆ¬è¿‡ï¼ˆé¿å…é‡å¤ï¼‰
    if not existing_df.empty:
        if ((existing_df['week'] == week) & (existing_df['date'] == release_date.strftime('%Y-%m-%d'))).any():
            print(f"  â­ï¸  ç¬¬ {week} å‘¨å·²å­˜åœ¨ï¼Œè·³è¿‡")
            continue

    print(f"æ­£åœ¨çˆ¬å–ç¬¬ {week} å‘¨ ({release_date.strftime('%Y-%m-%d')}) ...")

    try:
        # ç¤¼è²Œè¯·æ±‚ï¼šæ·»åŠ  User-Agent
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code != 200:
            print(f"  âš ï¸  é¡µé¢ä¸å­˜åœ¨ï¼ˆçŠ¶æ€ç  {response.status_code}ï¼‰ï¼Œè·³è¿‡")
            continue

        soup = BeautifulSoup(response.content, 'html.parser')
        table = soup.find('table')
        if not table:
            print(f"  âš ï¸  æ— è¡¨æ ¼ï¼Œè·³è¿‡")
            continue

        rows = table.find_all('tr', class_='rrow')
        if not rows:
            print(f"  âš ï¸  æ— æ•°æ®è¡Œï¼Œè·³è¿‡")
            continue

        for i, row in enumerate(rows):
            if i >= 50:
                break
            cols = row.find_all('td')
            if len(cols) < 4:
                continue


            try:
                # Rank: ä»Žç¬¬ä¸€ä¸ª td çš„ text æå–æ•°å­—ï¼ˆä¸æ˜¯ spanï¼‰
                rank_text = cols[0].text.strip()
                rank_match = re.search(r'\d+', rank_text)
                if not rank_match:
                    continue
                rank = int(rank_match.group())

                # Name
                player = cols[1].text.strip()

                # association
                association = extract_association(cols[2])

                # Points: åŽ»é™¤é€—å·ã€ç©ºæ ¼ç­‰éžæ•°å­—å­—ç¬¦
                points_text = cols[3].text.strip()
                clean_points = re.sub(r'[^\d]', '', points_text)
                points = int(clean_points) if clean_points else None

                # æ·»åŠ æ•°æ®
                info = {
                    "date": release_date.strftime('%Y-%m-%d'),
                    "week": week,
                    "rank": rank,
                    "player_name": player,
                    "association": association,
                    "points": points
                }
                print(info)
                new_data.append(info)

            except Exception as e:
                print(f"  âš ï¸  è§£æžå¤±è´¥: {e}")
                continue

            # try:
            #     # Rank
            #     rank_span = cols[0].find('span', class_='rank')
            #     if not rank_span:
            #         continue
            #     rank_text = rank_span.text.strip()
            #     rank = int(re.findall(r'\d+', rank_text)[0])

            #     # Name
            #     player = cols[1].text.strip()

            #     # Assoc
            #     assoc_p = cols[2].find('p', class_='fg')
            #     country = assoc_p['class'][1].replace('fg-', '') if assoc_p else None

            #     # Points
            #     points_text = cols[3].text.strip()
            #     points = int(points_text.replace(',', '')) if points_text.isdigit() else None
            #     info={
            #         "date": release_date.strftime('%Y-%m-%d'),
            #         "week": week,
            #         "rank": rank,
            #         "player_name": player,
            #         "country": country,
            #         "points": points
            #     }
            #     print(info)
            #     new_data.append({
            #         "date": release_date.strftime('%Y-%m-%d'),
            #         "week": week,
            #         "rank": rank,
            #         "player_name": player,
            #         "country": country,
            #         "points": points
            #     })

            # except Exception as e:
            #     print(f"  âš ï¸  è§£æžå¤±è´¥: {e}")
            #     continue


        print(f"  âœ… æˆåŠŸçˆ¬å– {len(rows)} æ¡è®°å½•")
        time.sleep(1.5)  # ç¤¼è²Œç­‰å¾… 1.5 ç§’

    except Exception as e:
        print(f"  âŒ é”™è¯¯: {e}")
        time.sleep(2)
        continue

# ====== 4. åˆå¹¶æ–°æ—§æ•°æ® ======
print(f"new_data é•¿åº¦: {len(new_data)}")

if new_data:
    new_df = pd.DataFrame(new_data)
    combined_df = pd.concat([existing_df, new_df], ignore_index=True)

    # å¯é€‰ï¼šæŒ‰ date + rank åŽ»é‡ï¼ˆé˜²æ­¢é‡å¤ï¼‰
    combined_df.drop_duplicates(subset=['date', 'rank'], keep='first', inplace=True)

    # æŒ‰æ—¥æœŸå’ŒæŽ’åæŽ’åºï¼ˆå¯é€‰ï¼‰
    combined_df['date'] = pd.to_datetime(combined_df['date'])
    combined_df = combined_df.sort_values(['date', 'rank']).reset_index(drop=True)
    combined_df['date'] = combined_df['date'].dt.strftime('%Y-%m-%d')

    # ä¿å­˜å›žåŽŸæ–‡ä»¶
    combined_df.to_csv(csv_file, index=False, encoding='utf-8-sig')
    print(f"\nðŸŽ‰ æ–°å¢ž {len(new_df)} æ¡è®°å½•ï¼Œæ€»è®°å½•æ•°: {len(combined_df)}")
else:
    print("\nâ„¹ï¸  æ²¡æœ‰æ–°æ•°æ®éœ€è¦æ·»åŠ ")