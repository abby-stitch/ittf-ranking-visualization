import requests
import pdfplumber
import pandas as pd
from datetime import datetime, timedelta
from io import BytesIO
import time

# ==============================
# é…ç½®
# ==============================
targetYear = 2021
csv_file = f"ittf_women_{targetYear}_7_rankings.csv"

# ==============================
# å·¥å…·å‡½æ•°ï¼šè®¡ç®—å‘å¸ƒæ—¥æœŸ
# ==============================
def get_ranking_release_date(year, week_num):
    jan_4 = datetime(year, 1, 4)
    monday_week1 = jan_4 - timedelta(days=jan_4.weekday())
    target_monday = monday_week1 + timedelta(weeks=week_num - 1)
    return target_monday + timedelta(days=1)

# ==============================
# åŠ è½½å·²æœ‰æ•°æ®
# ==============================
try:
    existing_df = pd.read_csv(csv_file)
    print(f"âœ… å·²åŠ è½½ {len(existing_df)} æ¡å·²æœ‰æ•°æ®")
except FileNotFoundError:
    existing_df = pd.DataFrame()
    print("âš ï¸ æœªæ‰¾åˆ°å·²æœ‰ CSVï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")

# ==============================
# ä¸»å¾ªç¯ï¼šçˆ¬å–ç¬¬1â€“52å‘¨
# ==============================
new_data = []

for week in range(7, 8):
    release_date = get_ranking_release_date(targetYear, week)
    year_dir = release_date.strftime('%Y')
    month_dir = release_date.strftime('%m')
    filename = f"WS-WR-{targetYear}.W{week}-v2.pdf"
    url = f"https://www.ittf.com/wp-content/uploads/{year_dir}/{month_dir}/{filename}"

    # è·³è¿‡å·²å­˜åœ¨
    if not existing_df.empty:
        if ((existing_df['week'] == week) & 
            (existing_df['date'] == release_date.strftime('%Y-%m-%d'))).any():
            print(f"  â­ï¸ ç¬¬ {week} å‘¨å·²å­˜åœ¨ï¼Œè·³è¿‡")
            continue

    print(f"æ­£åœ¨çˆ¬å–ç¬¬ {week} å‘¨ ({release_date.strftime('%Y-%m-%d')}) ...")

    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code != 200:
            print(f"  âš ï¸ é¡µé¢ä¸å­˜åœ¨ï¼ˆçŠ¶æ€ç  {response.status_code}ï¼‰ï¼Œè·³è¿‡")
            continue

        # # ç”¨ BytesIO åŒ…è£…
        # pdf_bytes = BytesIO(response.content)
        # with pdfplumber.open(pdf_bytes) as pdf:
        #     page = pdf.pages[0]
        #     text_lines = page.extract_text().split('\n')

        #     # è¿‡æ»¤æ‰æ ‡é¢˜ã€ç©ºç™½è¡Œ
        #     data_lines = []
        #     for line in text_lines:
        #         line = line.strip()
        #         if not line or line.startswith('Rank') or line.startswith('WOMEN'):
        #             continue
        #         if len(line.split()) < 3:  # è‡³å°‘æœ‰ Rank, Name, Assoc.
        #             continue
        #         data_lines.append(line)

        #     # æ‰‹åŠ¨è§£ææ¯ä¸€è¡Œ
        #     for line in data_lines:
        #         parts = line.split()
        #         if len(parts) < 4:
        #             continue

        #         # æ¨æµ‹ç»“æ„ï¼š[Rank] [Name...] [Assoc.] [Points]
        #         rank_str = parts[0]
        #         name_parts = parts[1:-2]  # ä¸­é—´åå­—éƒ¨åˆ†
        #         assoc = parts[-2]
        #         points_str = parts[-1]

        #         # æ¸…ç†
        #         rank = int(rank_str)
        #         name = ' '.join(name_parts)
        #         points = int(points_str.replace(',', ''))

        #         info = {
        #             "date": release_date.strftime('%Y-%m-%d'),
        #             "week": week,
        #             "rank": rank,
        #             "player_name": name,
        #             "association": assoc,
        #             "points": points
        #         }
        #         new_data.append(info)
        #         print(f"  âœ… æ·»åŠ : {name} ({assoc}) - {points}åˆ†")

        # ç”¨ BytesIO åŒ…è£…
        pdf_bytes = BytesIO(response.content)
        parsed_count = 0  # å·²è§£æçš„æœ‰æ•ˆè®°å½•æ•°

        with pdfplumber.open(pdf_bytes) as pdf:
            for page in pdf.pages:
                if parsed_count >= 50:
                    break
                text = page.extract_text()
                if not text:
                    continue
                text_lines = text.split('\n')

                # è¿‡æ»¤æ‰æ ‡é¢˜ã€ç©ºç™½è¡Œ
                data_lines = []
                for line in text_lines:
                    line = line.strip()
                    if not line or line.startswith(('Rank', 'WOMEN', 'World', 'ITTF', 'Page')):
                        continue
                    if len(line.split()) < 3:  # è‡³å°‘æœ‰ Rank, Name, Assoc.
                        continue
                    data_lines.append(line)

                # æ‰‹åŠ¨è§£ææ¯ä¸€è¡Œ
                for line in data_lines:
                    if parsed_count >= 50:
                        break

                    parts = line.split()
                    if len(parts) < 4:
                        continue

                    # æ¨æµ‹ç»“æ„ï¼š[Rank] [Name...] [Assoc.] [Points]
                    try:
                        rank = int(parts[0])
                        if rank > 50:  # å®‰å…¨å…œåº•ï¼šè·³è¿‡ rank > 50 çš„è¡Œ
                            continue
                        name = ' '.join(parts[1:-2])
                        assoc = parts[-2]
                        points = int(parts[-1].replace(',', ''))
                    except (ValueError, IndexError):
                        continue

                    info = {
                        "date": release_date.strftime('%Y-%m-%d'),
                        "week": week,
                        "rank": rank,
                        "player_name": name,
                        "association": assoc,
                        "points": points
                    }
                    new_data.append(info)
                    parsed_count += 1
                    print(f"  âœ… æ·»åŠ : {name} ({assoc}) - {points}åˆ†")

                print(f"  âœ… æˆåŠŸè§£æç¬¬ {week} å‘¨")
                time.sleep(2)

    except Exception as e:
        print(f"  âŒ é”™è¯¯: {e}")
        time.sleep(3)
        continue

# ==============================
# ä¿å­˜ç»“æœ
# ==============================
if new_data:
    new_df = pd.DataFrame(new_data)
    combined_df = pd.concat([existing_df, new_df], ignore_index=True)

    # å»é‡ + æ’åº
    combined_df.drop_duplicates(subset=['date', 'rank'], keep='first', inplace=True)
    combined_df['date'] = pd.to_datetime(combined_df['date'])
    combined_df = combined_df.sort_values(['date', 'rank']).reset_index(drop=True)
    combined_df['date'] = combined_df['date'].dt.strftime('%Y-%m-%d')

    # ä¿å­˜
    combined_df.to_csv(csv_file, index=False, encoding='utf-8-sig')
    print(f"\nğŸ‰ æ–°å¢ {len(new_df)} æ¡è®°å½•ï¼Œæ€»è®°å½•æ•°: {len(combined_df)}")
else:
    print("\nâ„¹ï¸ æ²¡æœ‰æ–°æ•°æ®éœ€è¦æ·»åŠ ")